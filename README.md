# ğŸ¤– Generative AI-Powered Data Analytics Platform

A comprehensive, modular AI-driven analytics platform that combines advanced machine learning, blockchain technology, federated learning, and natural language processing to provide end-to-end data analytics solutions.

## ğŸŒŸ Features

### Core Analytics Modules
- **ğŸ“Š Data Upload & Management** - Support for CSV, Excel, and various data formats
- **ğŸ§¹ Data Cleaning & Preprocessing** - Automated data quality improvements and feature engineering
- **ğŸ“ˆ Advanced Analytics** - Statistical analysis, correlation studies, and insights generation
- **ğŸ¤– AI Data Generation** - Synthetic data creation using advanced generative models
- **ğŸ’¡ AI-Powered Insights** - Machine learning-driven recommendations and pattern detection

### Advanced AI & ML
- **ğŸ§  Advanced ML Models & AutoML** - 20+ algorithms with automated hyperparameter optimization
- **ğŸ—ï¸ Ensemble Methods** - Voting, bagging, boosting, and stacking classifiers
- **ğŸ§  Deep Learning Simulation** - Neural network architectures and training
- **ğŸ“Š Model Comparison & Analysis** - Comprehensive model evaluation and benchmarking

### Cutting-Edge Technologies
- **ğŸ”— Blockchain Manager** - Data integrity, audit trails, and smart contracts
- **ğŸ¤ Federated Learning** - Multi-party machine learning with privacy preservation
- **ğŸ—£ï¸ Natural Language Query** - Chat with your data using conversational AI
- **ğŸ® Scenario Simulation** - What-if analysis and predictive modeling
- **âš¡ System Optimizer** - Performance optimization and resource management

### Interactive Dashboards
- **ğŸ“Š Dynamic Dashboard** - Real-time visualizations and interactive charts
- **ğŸ“‹ System Logs** - Comprehensive logging and monitoring

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8 or higher
- pip package manager
- 4GB+ RAM recommended
- Modern web browser

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/shaikhamzasaifuddin402/Ai-data-analyst.git
   cd Ai-data-analyst
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the application**
   ```bash
   streamlit run app.py
   ```

4. **Access the platform**
   Open your browser and navigate to `http://localhost:8501`

## ğŸ“– Usage Guide

### Getting Started
1. **Upload Data**: Start by uploading your dataset in the "ğŸ“¤ Data Upload" tab
2. **Clean Data**: Use the "ğŸ§¹ Data Cleaning" tab to preprocess your data
3. **Explore Analytics**: Navigate through various analysis tabs based on your needs
4. **Generate Insights**: Use AI-powered features for automated insights and recommendations

### Key Workflows

#### Basic Analytics Workflow
```
Data Upload â†’ Data Cleaning â†’ Advanced Analytics â†’ AI Insights â†’ Dynamic Dashboard
```

#### Advanced ML Workflow
```
Data Upload â†’ Data Cleaning â†’ Advanced ML Models â†’ Model Comparison â†’ Results Export
```

#### Blockchain Audit Workflow
```
Data Upload â†’ Blockchain Registration â†’ Smart Contract Deployment â†’ Audit Trail Review
```

## ğŸ—ï¸ Architecture

### System Components
- **Frontend**: Streamlit-based web interface
- **Backend**: Modular Python agents for specialized tasks
- **AI Core**: Generative analytics engine with multiple ML models
- **Blockchain**: Distributed ledger for data integrity
- **Storage**: Session-based data management with optional persistence

### Module Structure
```
â”œâ”€â”€ app.py                 # Main application entry point
â”œâ”€â”€ config.py             # Configuration settings
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ agents/              # Core functionality modules
â”‚   â”œâ”€â”€ data_processor.py
â”‚   â”œâ”€â”€ ai_core.py
â”‚   â”œâ”€â”€ blockchain_manager.py
â”‚   â”œâ”€â”€ federated_learning.py
â”‚   â”œâ”€â”€ advanced_ml_models.py
â”‚   â””â”€â”€ ...
â””â”€â”€ utils/               # Utility functions
    â””â”€â”€ data_generator.py
```

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file in the root directory:
```env
OPENAI_API_KEY=your_openai_api_key_here
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost
```

### Advanced Configuration
Modify `config.py` to customize:
- Model parameters
- Performance settings
- Security configurations
- Feature toggles

## ğŸ§© Optional NLP Dependencies
- The app now guards optional NLP imports. If `transformers` or TensorFlow is not available or incompatible, NLP features are gracefully disabled and the rest of the app continues to run.
- If you want Transformer pipelines enabled with TensorFlow, and you encounter the Keras 3 compatibility error, you can:
  - Install `tf-keras` (`pip install tf-keras`), or
  - Prefer PyTorch backend (`pip install torch`) to avoid TensorFlow/Keras coupling, or
  - Disable TensorFlow in Transformers by setting `TRANSFORMERS_NO_TF=1` in your environment.

## ğŸ“Š Supported Data Formats

- **CSV Files** (.csv)
- **Excel Files** (.xlsx, .xls)
- **JSON Files** (.json)
- **Parquet Files** (.parquet)
- **Data Connectors** (optional; add SQL/MongoDB if needed)

## ğŸ¤– AI Models & Algorithms

### Machine Learning Algorithms
- **Classification**: Random Forest, SVM, Gradient Boosting, Neural Networks
- **Regression**: Linear/Polynomial Regression, Ridge, Lasso, ElasticNet
- **Clustering**: K-Means, DBSCAN, Hierarchical Clustering
- **Ensemble Methods**: Voting, Bagging, Boosting, Stacking

### Deep Learning Models
- **Neural Networks**: Feedforward, CNN, RNN, LSTM
- **Generative Models**: GANs, VAEs, Transformers
- **AutoML**: Automated model selection and hyperparameter tuning

## ğŸ” Security & Privacy

### Blockchain Features
- **Data Integrity**: Cryptographic hashing and verification
- **Audit Trails**: Immutable transaction records
- **Smart Contracts**: Automated data validation rules

### Privacy Protection
- **Federated Learning**: Decentralized model training
- **Differential Privacy**: Statistical privacy guarantees
- **Secure Multi-party Computation**: Privacy-preserving analytics

## ğŸ§ª Testing

### Running Tests
```bash
# Install test dependencies
pip install pytest pytest-cov

# Run all tests
pytest tests/

# Run with coverage
pytest --cov=agents tests/
```

### Test Coverage
- Unit tests for all core modules
- Integration tests for workflows
- Performance benchmarks
- Security validation tests

## ğŸ“ˆ Performance

### Optimization Features
- **Caching**: Streamlit caching for improved performance
- **Lazy Loading**: On-demand module loading
- **Memory Management**: Efficient data handling
- **Parallel Processing**: Multi-threaded computations

### Scalability
- Supports datasets up to 10M+ rows
- Distributed computing capabilities
- Cloud deployment ready
- Edge computing support

## ğŸ¤ Contributing

### Development Setup
1. Fork the repository
2. Create a feature branch
3. Install development dependencies: `pip install -r requirements-dev.txt`
4. Make your changes
5. Run tests: `pytest`
6. Submit a pull request

### Code Standards
- Follow PEP 8 style guidelines
- Add docstrings to all functions
- Include unit tests for new features
- Update documentation as needed

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

### Common Issues
- **Import Errors**: Ensure all dependencies are installed
- **Memory Issues**: Reduce dataset size or increase system RAM
- **Performance**: Enable caching and optimize data types

### Getting Help
- Check the [Issues](issues) page for known problems
- Review the documentation for detailed usage instructions
- Contact the development team for technical support

## ğŸ”® Future Roadmap

### Planned Features
- **Real-time Data Streaming** - Live data processing capabilities
- **Advanced Visualization** - 3D plots and interactive dashboards
- **API Integration** - RESTful API for external integrations
- **Mobile Support** - Responsive design for mobile devices
- **Multi-language Support** - Internationalization features

### Research Areas
- **Quantum Computing Integration** - Quantum-enhanced algorithms
- **Explainable AI** - Enhanced model interpretability
- **Edge AI** - Lightweight models for edge deployment
- **Automated Feature Engineering** - AI-driven feature creation

---

**Built with â¤ï¸ using Python, Streamlit, and cutting-edge AI technologies**

For more information, visit our [documentation](docs/) or contact the development team.